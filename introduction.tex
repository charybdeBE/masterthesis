In several domains, multi-gigapixel images must be analysed for the purpose of gathering information and/or for taking decisions. Typically, the information is represented by the presence of a series of objects of interest which are embedded into the image. The aim of the analysis is to locate and identify those objects. Depending on the problem and  specific field of application, the extracted objects can be used for various purposes. For instance, in cytology, digitized microscope slides containing human tissues are analysed by physicians in order to diagnose particular diseases, the disease in question manifesting itself by the presence of cells having certain characteristics. In geology, slides containing core samples can be digitized and analysed to find concentration of certain micro-organisms.

Those images are usually analysed manually by experts. However, due to the size of the problem, the analysis is not always performed exhaustively. When possible, experts typically select a reduced number of regions to study and draw conclusions from the observations performed in those regions. This process has obviously the drawback of increasing the risk of missing objects of interest.

Because of the risk yielded by the previous method and because manual analysis of full images is long and tedious, computer programs could be used to assist experts. For instance, those programs could indicate which regions are worth analysing and which are not. They could also perform the search for the expert under his supervision: that is, the expert would be able to provide a feedback to the program which could then improve its detection process. 

In order to provide this assistance and to learn from experts' feedbacks, image processing and machine learning are used. Whereas IP and ML provide a complete toolbox of algorithms for computer vision in general, they are however not necessarily well suited for handling large images. Especially, typical implementations of those algorithms implicitly make the assumption that the full image can be loaded into memory which is not always possible. Indeed, multi-gigapixel images typically require several gigabytes of memory. The execution times of those algorithms generally grow with the size of the image, yielding unacceptable execution times. Parallelism can alleviate this problem but, again, typical implementations do not necessarily support this feature. Therefore, when diving into a new problem of object detection, implementers typically develop workflows by combining machine learning and image processing algorithms to handle detection but they also have to deal with problem-independent concerns such as parallelism or memory constraints. 

This thesis proposes \textit{SLDC}, a generic framework for solving problems of object detection and classification in multi-gigapixel images. Especially, it provides implementers with a structure to define problem-dependent components of the algorithm (i.e. detection and classification) in a concise way. Every other concerns such as parallelization and large image handling are encapsulated by the framework. It also provides a way to execute several processing workflows one after another on the same image as well as a powerful and customizable logging system. Typically, when facing a new problem of object detection and classification, an implementer instantiates the framework into a workflow to deal with this problem. 

In Chapter \ref{chap:context}, the problem of object detection and classification is introduced and its application to different cases is presented. In Chapter \ref{chap:work_intro}, the framework and its implementation are presented. In Chapter \ref{chap:thyroid}, the framework is applied to a cytology problem, the thyroid case.