\section{Principle}
\subsection{History and first developments}
\label{ssec:history_first_dev}
The Segment-Locate-Dispatch-Classify (SLDC) workflow was first imagined by ?? Jean-Michel Begon ?? as a generalization of the work on thyroid nodule malignancy detection made in \cite{adeblire2013}. In the context of this master thesis, the author had implemented a processing workflow for detecting cells with inclusion and proliferative patterns (see ?? (thyroid)) in digitized thyroid punctions slides. The cells and patterns were detected by segmenting the images and then classified using machine learning techniques. As explained in the Section ?? (thyroid), patterns could themselves contain cells with inclusion. Therefore, the author implemented a second processing workflow to detect those cells. This workflow was similar to the first because it relied on a segmentation algorithm to isolate cells in patterns and then used machine learning to assess their malignity. 

From those workflows, a common pattern emerged: performing detection using a segmentation algorithm and then classifying the detected objects using machine learning techniques. This pattern was at the root of the SLDC workflow idea. 

\subsection{Algorithm}
\label{ssec:workflow_algo}
The workflow is a meta-algorithm\footnote{In this context, a meta-algorithm is an algorithm that coordinates the execution of other algorithms.} that detects and classifies objects contained in images. Particularly, given an image $\mathcal{I}$ as input, it is expected to output the information about the objects of interest in this image. Those information include the shape of the object, its location in the image as well as a classification label. Formally, the workflow can be seen as an operator $\mathcal{W}$:

\begin{definition} Let $\mathcal{W}$ be an operator such that 
	\begin{equation}\label{eqn:workflow_operator}
		\mathcal{W}(\cdot) : \mathcal{I} \rightarrow \left\{(o_1,C_1),...,(o_N, C_N)\right\}
	\end{equation}
	where $N$ is the number of objects of interest in $\mathcal{I}$ and $(o_i, C_i)$ is a tuple. The first element of this tuple, $o_i$, is a representation of the information (shape and location) about the $i^{th}$ object of interest found in $\mathcal{I}$ and the second, $C_i$, its classification label. 
\end{definition}

It is worth noting that genericity is of the essence. That is, the meta-algorithm should be able to solve the widest possible range of object detection and classification problems. Moreover, as explained in Section \ref{ssec:history_first_dev}, it should produce those outputs using image segmentation and machine learning. As far as the segmentation is concerned, genericity is usually hard to obtain because of the high variability of images across different problems. In order to ensure genericity, the workflow doesn't impose a particular segmentation procedure but expects the implementer to provide one that suits the problem. The same goes for the classification models used for predicting the labels of the objects. 

In the subsequent sections, some additional operators are defined and used to build the $\mathcal{W}$ operator. First, a basic version of the algorithm is presented and then refined in order to achieve an acceptable level of genericity.

\subsection{Additional operators}
\label{ssec:other_operators}

Segmentation is the first operation applied to the image. This step of the algorithm is where the detection is actually carried out:
 
\begin{definition} \label{def:segmentation_op}
Let $\mathcal{S}$ be the \textbf{segment} operator. It is applied to an image $\mathcal{I}$ and produces a binary mask $\mathcal{B}$. The pixel $b_{ij}$ of $\mathcal{B}$ is 1 if the pixel $p_{ij}$ of $\mathcal{I}$ is located in an object of interest, otherwise it is 0. Formally:
\begin{equation}
	\label{eqn:operator_segment}
	\mathcal{S}(\cdot) : \mathcal{I} \rightarrow \mathcal{B}
\end{equation}
\end{definition}

While the segmented image theoretically contains the necessary information about the detected objects (i.e. shape and position in the image), the format of this information is inconvenient to query mostly because it is embedded into the binary mask and a single object cannot be trivially extracted. An intermediate step that would convert this information into a more convenient format is therefore needed. This format should encode both the shape of the object and its position in the image. It appears that polygons match this specification. 

\begin{definition} \label{def:locate_op}
Let $\mathcal{L}$ be the \textbf{location} operator. It is applied to a binary mask and produces a set of polygons encoding the shapes and positions of every object in the image. Formally:

\begin{equation}
	\mathcal{L}(\cdot) : \mathcal{B} \rightarrow \left\{P_1, ..., P_N\right\}
\end{equation}

where $\mathcal{B}$ is a binary mask as defined in Definition \ref{def:segmentation_op}, $N$ is the number of objects of interest in $\mathcal{B}$ and $P_i$ is the polygon representing the geometric contour of the $i^{th}$ object in $\mathcal{B}$.
\end{definition}

The final step of the workflow is the object classification and is performed by a classifier. This object is passed a representation of the object (e.g. image, geometric information,...) and produces a classification label. In this theory, there is no restriction about the nature or representation of the objects processed by the classifiers.

\begin{definition} Let $\mathcal{T}$ be the \textbf{classifier} operator. It is applied to an object of interest and produces a classification label. Formally:
\begin{equation}
	\mathcal{T}(\cdot) : o \rightarrow C
\end{equation}
where $o$ is the object and $C$, the classification label. 
\end{definition}
\begin{definition}
Let $\mathcal{T}^*$ be an extension of $\mathcal{T}$ which is given a set of objects and produces labels for all of them. Formally: 
\begin{equation}
	\mathcal{T}^*(\cdot) : \left\{o_1, ..., o_N\right\}  \rightarrow \left\{C_1, ..., C_N\right\}
\end{equation}
\end{definition}

\subsection{Single segmentation, single classifier}
\label{ssec:single_single}

The most simple construction of $\mathcal{W}$ would be the composition of the operators defined in Section \ref{ssec:other_operators}. Particularly, the composition $\mathcal{S} \circ \mathcal{L}$ would produce the polygons representing the objects and the composition $\mathcal{S} \circ \mathcal{L} \circ \mathcal{T}^*$ would produce the labels. Formally: 

\begin{eqnarray}
	\label{eqn:segment_locate_base} \mathcal{S} \circ \mathcal{L} : \mathcal{I} \rightarrow \left\{P_1, ..., P_N\right\} \\
	\mathcal{S} \circ \mathcal{L} \circ \mathcal{T}^* : \mathcal{I} \rightarrow \left\{C_1, ..., C_N\right\}
\end{eqnarray}

As explained in Section \ref{ssec:workflow_algo}, the definition of $\mathcal{S}$ and $\mathcal{T}^*$ would be left at the implementer's hands. As far as the $\mathcal{L}$ operator is concerned, it could be imposed by the workflow without loss of genericity. Such an construction of $\mathcal{W}$ could already solve any object detection and classification problem on image in which the labels can be predicted by a single classifier. However, in some cases, one classifier is not enough. This happen, for instance, when the image contains objects of very different nature and using several classifiers would yield better results than using a single one. An extension is therefore needed.

\subsection{Single segmentation, several classifiers}
\label{ssec:single_several}

In this attempt to construct a generic $\mathcal{W}$ operator, the image is assumed to contain $M$ distinct types of objects and the workflow uses $M$ classifiers (the $i^{th}$ classifier being noted as $\mathcal{T}_i$ with $i \in \{1,...,M\}$) to classify those objects. As an object should only be processed by one classifier, the workflow has to be added a new step which consists in dispatching each polygon to its most appropriate classifier. 

\begin{definition}\label{def:dispatch_op} 
	Let $\mathcal{D}$ be the dispatch operator. It is applied to a polygon and produces an integer which identifies the most appropriate classifier for processing this polygon: 

	\begin{equation}
		\mathcal{D}(\cdot) : P \rightarrow i, i \in \{1,...,M\}
	\end{equation}
\end{definition}

This step being problem dependent, it is the responsibility of the implementer to define the rules used for dispatching the polygons. However, the format of these rules can be defined.

\begin{definition} 
	Let $\mathcal{P}$ be a set of $M$ predicates $p_1, ..., p_M$ which associate truth values to polygons:
	\begin{equation}
		p_i(\cdot) : P \rightarrow t \in \{true, false\}, i \in \left\{1,...,M\right\} 
	\end{equation}
	where $p_i$ is the predicate associated with the $i^{th}$ classifier. The polygon $P$ is dispatched to a classifier $\mathcal{T}_i$ if $p_i$ associates true to this polygon. To avoid dispatching an object to several classifier, the predicates should verify the following property:
	\begin{equation}
		p_i = true \Leftrightarrow p_j = false, \forall j \neq i
	\end{equation} 
\end{definition}

Given this format, the $\mathcal{D}$ operator can be trivially constructed as it returns $i$ if $p_i$ is \textit{true}. The algorithm resulting from this construction of $\mathcal{W}$ starts the same way as in Section \ref{ssec:single_single}: the image is applied the segment and locate operators (see Equation \ref{eqn:segment_locate_base}). Then, the resulting polygons are dispatched and classified to produce the classification label. The resulting algorithm is summarized in Algorithm \ref{algo:single_seg_several_classif}. 

While the range of problems that can be solved using this algorithm has been increased compared to the version with a single classifier, there are still some problems that cannot be. In particular, if some objects are included into other bigger objects, they won't be considered as independent objects.

\begin{algorithm}\label{algo:single_seg_several_classif}
Construction of the $\mathcal{W}$ operator with a single segmentation and several classifiers. 
\begin{enumerate}
	\item Apply the $\mathcal{S} \circ \mathcal{L}$ composition to the input image $\mathcal{I}$ to extract the objects of interest as the set of polygons $S_p \leftarrow \left\{P_1, ..., P_N \right\}$
	\item Initialize the labels set $L \leftarrow \emptyset$
	\item For each polygon $P \in S_p$:
	\begin{enumerate}
		\item Compute the classification label $C \leftarrow \mathcal{T}_{\mathcal{D}(P)}(P)$
		\item Place the label in the labels set $L \leftarrow L \cup \{C\}$
	\end{enumerate}
	\item Build and return objects and labels set $S_p \times L$.
\end{enumerate}
\end{algorithm}

\subsection{Chaining workflows}

To take into account the case when objects of interest can be included into objects of bigger size in the image, several instances of Algorithm \ref{algo:single_seg_several_classif} can be executed sequentially. 

\begin{definition}\label{def:several_w_op}
	Let $\mathcal{W}_1, ..., \mathcal{W}_K$ be a set of $K$ instances of Algorithm \ref{algo:single_seg_several_classif}. Each algorithm $\mathcal{W}_i$ has its own segmentation procedure $\mathcal{S}_i$ and its sets of dispatching predicates $\mathcal{P}_i$ and classifiers $S_{\mathcal{T},i}$.
\end{definition}

While $\mathcal{W}_1$ would be applied to the full image $\mathcal{I}$ to extract all the objects of interest, $\mathcal{W_2}, ..., \mathcal{W_K}$ are only passed image windows containing the previously detected objects.

\begin{definition}\label{def:image_window}
	Let $\mathcal{I}_P$ be an image window extracted from image $\mathcal{I}$ and containing the object represented by the polygon $P$. The window is the minimum bounding box containing this polygon.
\end{definition}

A further refinement would be to provide a way for the implementer to filter the polygons of which the windows are passed to a given workflow instance. Indeed, a given instance $\mathcal{W}_i$ might be designed to process only a certain category of objects and therefore should not be passed windows of objects that doesn't fall in this category. 

\begin{definition}\label{def:filter_op}
	Let $\mathcal{F}$ be the $\textbf{filter}$ operator. It is given a set of polygons $S_P$ and returns a subset $S'_P$ of polygons:
	
	\begin{equation}
		\mathcal{F}(\cdot): S_P \rightarrow S'_P, S'_P \subseteq S_P
	\end{equation}
\end{definition}

Each instance of the workflow $\mathcal{W}_i$ except $\mathcal{W}_1$ is therefore associated a filter operator $\mathcal{F}_i$. The resulting algorithm is given in Algorithm \ref{algo:chaining_workflows}.

\begin{algorithm} \label{algo:chaining_workflows}
	Construction of the $\mathcal{W}$ operator with $K$ instances of Algorithm \ref{algo:single_seg_several_classif}:

	\begin{enumerate}
		\item Execute the first workflow and save the results in the results set $R$: $R \leftarrow \mathcal{W}_1(\mathcal{I})$
		\item Create the polygons set and initializes it with the polygons found from the execution of $\mathcal{W}_1$: $S_P \leftarrow \left\{P_1, ..., P_N\right\}$
		\item For $i \in \{2, ..., K\}$:
		\begin{enumerate}
			\item Extract polygons to be processed by $\mathcal{W}_i$: $S'_P \leftarrow \mathcal{F}_i(S_P)$
			\item For polygon $P \in S'_P$:
			\begin{enumerate}
				\item Execute the workflow on the image window and saves the results: $R \leftarrow R \cup \mathcal{W}_i(\mathcal{I}_P)$
				\item Add the extracted polygons to the polygons set: $S_P \leftarrow S_P \cup \left\{P_1, ..., P_M\right\}$
			\end{enumerate}
		\end{enumerate}
		\item Return the results set $R$
	\end{enumerate}
\end{algorithm}

\subsection{Summary}
The resulting meta-algorithm as defined in Algorithm \ref{algo:chaining_workflows} has now reached an acceptable level of genericity. The user would have to define


\section{Implementation}
\subsection{Framework}

Describe what we expect from a framework implementing the workflow (parallism, easy to use,...) 

As explained in Section \ref{ssec:history_first_dev}, a first version of the workflow was developed in the context of Cytomine. 
\subsection{Technologies}

\subsection{Software architecture}
Detail of the software architecture
\subsection{How to use the framework}
A toy example: finding disks in an image with grey background and guessing whether they're black or white 